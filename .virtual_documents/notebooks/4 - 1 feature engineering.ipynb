import pandas as pd



# Load the datasets
original_sales_data = pd.read_csv('../data/snp_dld_2024_transactions.csv', low_memory=False)
original_rentals_data = pd.read_csv('../data/snp_dld_2024_rents.csv', low_memory=False)
# Load the processed dfs
sales_data = pd.read_csv('../data/sales_data_no_missing.csv', low_memory=False)
rentals_data = pd.read_csv('../data/rentals_data_no_missing.csv', low_memory=False)


sales_data.info()





sales_data['area_en'].isnull().sum()


len(sales_data['area_en'].unique())


unique_area_count = sales_data['area_en'].nunique()
print("Number of unique values in 'area_en':", unique_area_count)



import time
import pandas as pd
from geopy.geocoders import Nominatim

geolocator = Nominatim(user_agent="geoapi")
geocoded_areas = {}

def fetch_lat_long_cached(area):
    if area in geocoded_areas:
        return geocoded_areas[area]
    try:
        location = geolocator.geocode(area)
        if location:
            geocoded_areas[area] = (location.latitude, location.longitude)
        else:
            geocoded_areas[area] = (None, None)
    except:
        geocoded_areas[area] = (None, None)
    return geocoded_areas[area]

# Apply geocoding with caching
sales_data['latitude'], sales_data['longitude'] = zip(
    *sales_data['area_en'].apply(fetch_lat_long_cached)
)

# Save cached results
pd.DataFrame.from_dict(geocoded_areas, orient='index', columns=['latitude', 'longitude']).to_csv("geocoded_areas.csv")

# Delay for API rate limits
time.sleep(1)



import os
import time
import pandas as pd
from geopy.geocoders import Nominatim
from concurrent.futures import ThreadPoolExecutor

# Initialize geolocator and cache
geolocator = Nominatim(user_agent="geoapi")
geocoded_areas = {}

# Load cached geocoded data if available
cache_file = "geocoded_areas.csv"
if os.path.exists(cache_file):
    print("Loading cached geocoded areas...")
    geocoded_areas_df = pd.read_csv(cache_file, index_col=0)
    geocoded_areas = {
        area: (row['latitude'], row['longitude'])
        for area, row in geocoded_areas_df.iterrows()
    }
else:
    print("No cache found. Starting fresh.")

# Function to fetch coordinates with caching
def fetch_lat_long_cached(area_en, area_ar):
    if area_en in geocoded_areas:
        return geocoded_areas[area_en]
    if area_ar in geocoded_areas:
        return geocoded_areas[area_ar]

    try:
        location = geolocator.geocode(area_en) or geolocator.geocode(area_ar)
        if location:
            geocoded_areas[area_en] = (location.latitude, location.longitude)
            return location.latitude, location.longitude
    except Exception as e:
        print(f"Error fetching {area_en}/{area_ar}: {e}")
    
    geocoded_areas[area_en] = (None, None)
    return None, None

# Function to apply geocoding in parallel
def process_row(row):
    return fetch_lat_long_cached(row['area_en'], row['area_ar'])




sales_data['area_ar'] = original_sales_data['area_ar']
# Perform geocoding with threading
print("Starting geocoding...")
start_time = time.time()
with ThreadPoolExecutor(max_workers=10) as executor:
    results = list(executor.map(
        process_row,
        [row for _, row in sales_data[['area_en', 'area_ar']].iterrows()]
    ))
end_time = time.time()
print(f"Geocoding completed in {end_time - start_time:.2f} seconds.")

# Update DataFrame with results
sales_data['latitude'], sales_data['longitude'] = zip(*results)

# Save updated geocoded data to cache
geocoded_areas_df = pd.DataFrame.from_dict(geocoded_areas, orient='index', columns=['latitude', 'longitude'])
geocoded_areas_df.to_csv(cache_file)
print(f"Cached geocoded areas saved to {cache_file}")
sales_data['latitude'], sales_data['longitude'] = zip(
    *sales_data.apply(lambda row: fetch_lat_long_cached(row['area_en'], row['area_ar']), axis=1)
)

# Save geocoded results
geocoded_df = pd.DataFrame.from_dict(geocoded_areas, orient='index')
geocoded_df.to_csv("fallback_geocoded_areas.csv")


# Convert geocoded_areas to a DataFrame with proper indexing
geocoded_df = pd.DataFrame.from_dict(geocoded_areas, orient='index', columns=['latitude', 'longitude'])

# Reset index to use area names properly
geocoded_df.index.name = 'area_en'
geocoded_df.reset_index(inplace=True)

# Check the updated DataFrame
print(geocoded_df.head())



geocoded_df


# Identify rows where latitude or longitude is None
missing_coords = geocoded_df[geocoded_df[['latitude', 'longitude']].isnull().any(axis=1)]

# Display areas with missing coordinates
missing_coords[['area_en', 'latitude', 'longitude']]



# Identify rows where both latitude and longitude are not null
non_missing_coords = geocoded_df[geocoded_df[['latitude', 'longitude']].notnull().all(axis=1)]

# Display areas with non-missing coordinates
print(non_missing_coords[['area_en', 'latitude', 'longitude']])




geocoded_df = pd.DataFrame.from_dict(
    geocoded_areas, orient="index", columns=["latitude", "longitude"]
)



missing_values = geocoded_df.isnull().sum()
print("Missing values in geocoded_df:")
print(missing_values)



geocoded_df


# Rename the columns to 'latitude' and 'longitude'
geocoded_df.columns = ['latitude', 'longitude']

# Verify the changes
print(geocoded_df.head())
print(geocoded_df.isnull().sum())



geocoded_df


# Number of unique area_en in the sales_data
unique_area_en_in_sales = sales_data['area_en'].nunique()

# Number of geocoded areas in the geocoded_areas dictionary
unique_geocoded_areas = len(geocoded_areas)

print(f"Number of unique areas in sales_data: {unique_area_en_in_sales}")
print(f"Number of successfully geocoded areas: {unique_geocoded_areas}")



import os
import pandas as pd
from geopy.geocoders import Nominatim
import time

# Initialize geolocator and load cache if available
geolocator = Nominatim(user_agent="geoapi")
geocoded_projects = {}

# Load cached projects if the file exists
project_cache_file = "geocoded_projects.csv"
if os.path.exists(project_cache_file):
    geocoded_projects = pd.read_csv(project_cache_file).set_index('project_name_en').T.to_dict(orient="list")

# Function to fetch latitude and longitude with caching
def fetch_lat_long_cached(entity, cache):
    if entity in cache:
        return cache[entity]
    try:
        location = geolocator.geocode(entity)
        if location:
            cache[entity] = (location.latitude, location.longitude)
        else:
            cache[entity] = (None, None)
    except:
        cache[entity] = (None, None)
    return cache[entity]

# Fill missing latitude and longitude
def fill_missing_coords(df, area_column, project_column):
    global geocoded_projects  # To allow caching
    missing_coords = df[df['latitude'].isnull() & df['longitude'].isnull()]
    
    for index, row in missing_coords.iterrows():
        area = row[area_column]
        project = row[project_column]
        
        # First, try using the area
        lat, lon = fetch_lat_long_cached(area, geocoded_projects)
        if lat is None or lon is None:
            # If area fails, fallback to project_name_en
            lat, lon = fetch_lat_long_cached(project, geocoded_projects)
        
        # Update DataFrame if coordinates were found
        if lat is not None and lon is not None:
            df.at[index, 'latitude'] = lat
            df.at[index, 'longitude'] = lon
    
    return df

# Apply the function to your DataFrame
sales_data = fill_missing_coords(sales_data, 'area_en', 'project_name_en')

# Save updated project geocodes to the cache file
project_df = pd.DataFrame.from_dict(geocoded_projects, orient='index', columns=['latitude', 'longitude'])
project_df.index.name = 'project_name_en'
project_df.reset_index().to_csv(project_cache_file, index=False)

print("Missing coordinates handled using project_name_en, and cache updated.")



# Check for missing latitude and longitude
missing_lat_lon = sales_data[['latitude', 'longitude']].isnull().sum()

# Display the count of missing values
print("Missing Latitude and Longitude Counts:")
print(missing_lat_lon)

# Optionally, display the rows where either latitude or longitude is missing
missing_rows = sales_data[sales_data['latitude'].isnull() | sales_data['longitude'].isnull()]
print(f"Total rows with missing latitude or longitude: {len(missing_rows)}")

# If you want to see a sample of these rows
print(missing_rows.head())


# Check for rows where latitude or longitude is still missing
missing_lat_lon_after_inference = geocoded_df[geocoded_df['latitude'].isnull() | geocoded_df['longitude'].isnull()]

# Get the count of unique area_en with missing coordinates
unique_missing_area_count = missing_lat_lon_after_inference['area_en'].nunique()

# Print the results
print(f"Number of area_en with missing latitude and longitude after inference: {unique_missing_area_count}")

# Optionally, display these area_en values
print("Areas with missing latitude and longitude:")
print(missing_lat_lon_after_inference['area_en'].unique())



# Group project_name_en by area_en
project_area_groups = sales_data.groupby('area_en')['project_name_en'].apply(list).reset_index()

# Rename columns for clarity
project_area_groups.columns = ['area_en', 'project_names']

# Display the grouped data
print(project_area_groups.head())

# Save to a file if needed
project_area_groups.to_csv("project_name_by_area_en.csv", index=False)



# Filter out rows where area_en or project_name_en is 'Unknown'
filtered_sales_data = sales_data[
    (sales_data['area_en'] != "Unknown") & (sales_data['project_name_en'] != "Unknown")
]

# Group project_name_en by area_en
project_area_groups = filtered_sales_data.groupby('area_en')['project_name_en'].apply(list).reset_index()

# Rename columns for clarity
project_area_groups.columns = ['area_en', 'project_names']

# Display the grouped data
print(project_area_groups.head())

# Save to a file if needed
project_area_groups.to_csv("project_name_by_area_en_filtered.csv", index=False)



# Identify area_en with missing latitude and longitude
missing_coords_areas = geocoded_df[geocoded_df['latitude'].isnull() & geocoded_df['longitude'].isnull()]['area_en']

# Filter project_area_groups for area_en with missing coordinates
missing_coords_projects = project_area_groups[project_area_groups['area_en'].isin(missing_coords_areas)]

# Display the filtered project names
print(missing_coords_projects)


missing_coords_projects.isnull().sum()


missing_coords_projects


from geopy.geocoders import Nominatim
import pandas as pd
import time

geolocator = Nominatim(user_agent="geoapi")
geocoded_projects = {}  # Cache for geocoded projects

def fetch_lat_long(address):
    """Fetch latitude and longitude for an address."""
    if address in geocoded_projects:
        return geocoded_projects[address]
    try:
        location = geolocator.geocode(address)
        if location:
            geocoded_projects[address] = (location.latitude, location.longitude)
            return location.latitude, location.longitude
    except Exception as e:
        pass
    geocoded_projects[address] = (None, None)
    return None, None

def infer_coords_from_projects(missing_coords_projects, geocoded_df):
    """Infer latitude and longitude for area_en using project_names."""
    updated_geocoded_df = geocoded_df.copy()
    for index, row in missing_coords_projects.iterrows():
        area = row['area_en']
        for project in row['project_names']:
            lat, lon = fetch_lat_long(project)
            if lat is not None and lon is not None:
                print(f"Found coordinates for {area} using project {project}: ({lat}, {lon})")
                updated_geocoded_df.loc[updated_geocoded_df['area_en'] == area, ['latitude', 'longitude']] = lat, lon
                break
        time.sleep(1)  # Avoid overloading the API
    return updated_geocoded_df

# Perform inference
updated_geocoded_df = infer_coords_from_projects(missing_coords_projects, geocoded_df)

# Save updated geocoded DataFrame
updated_geocoded_df.to_csv("updated_geocoded_areas.csv", index=False)

# Display remaining missing coordinates
remaining_missing = updated_geocoded_df[updated_geocoded_df['latitude'].isnull() & updated_geocoded_df['longitude'].isnull()]
print(f"Number of area_en with missing coordinates after inference: {len(remaining_missing)}")



from geopy.geocoders import Nominatim
import pandas as pd
import time

geolocator = Nominatim(user_agent="geoapi")
geocoded_landmarks = {}  # Cache for geocoded landmarks

def fetch_lat_long_landmark(address):
    """Fetch latitude and longitude for a landmark."""
    if address in geocoded_landmarks:
        return geocoded_landmarks[address]
    try:
        location = geolocator.geocode(address)
        if location:
            geocoded_landmarks[address] = (location.latitude, location.longitude)
            return location.latitude, location.longitude
    except Exception as e:
        pass
    geocoded_landmarks[address] = (None, None)
    return None, None

def infer_coords_from_landmarks(missing_coords_landmarks, geocoded_df):
    """Infer latitude and longitude for area_en using nearest_land_mark_en."""
    updated_geocoded_df = geocoded_df.copy()
    for index, row in missing_coords_landmarks.iterrows():
        area = row['area_en']
        for landmark in row['nearest_landmarks']:
            lat, lon = fetch_lat_long_landmark(landmark)
            if lat is not None and lon is not None:
                print(f"Found coordinates for {area} using landmark {landmark}: ({lat}, {lon})")
                updated_geocoded_df.loc[updated_geocoded_df['area_en'] == area, ['latitude', 'longitude']] = lat, lon
                break
        time.sleep(1)  # Avoid overloading the API
    return updated_geocoded_df

# Group nearest_land_mark_en by area_en for missing areas
missing_coords_landmarks = remaining_missing.merge(
    sales_data[['area_en', 'nearest_landmark_en']].drop_duplicates(),
    on='area_en',
)
missing_coords_landmarks = missing_coords_landmarks.groupby('area_en')['nearest_landmark_en'].apply(list).reset_index(name='nearest_landmarks')

# Perform inference
updated_geocoded_df_landmarks = infer_coords_from_landmarks(missing_coords_landmarks, updated_geocoded_df)

# Save updated geocoded DataFrame
updated_geocoded_df_landmarks.to_csv("final_geocoded_areas.csv", index=False)

# Display remaining missing coordinates
remaining_missing_landmarks = updated_geocoded_df_landmarks[
    updated_geocoded_df_landmarks['latitude'].isnull() & updated_geocoded_df_landmarks['longitude'].isnull()
]
print(f"Number of area_en with missing coordinates after inferring from landmarks: {len(remaining_missing_landmarks)}")






# Step 1: Reset invalid coordinates derived from 'Unknown'
def reset_invalid_coordinates(df):
    invalid_coords = (df['latitude'] == 26.49253305) & (df['longitude'] == 92.33087891709363)
    df.loc[invalid_coords, ['latitude', 'longitude']] = None
    return df

updated_geocoded_df_landmarks = reset_invalid_coordinates(updated_geocoded_df_landmarks)


from geopy.geocoders import Nominatim
import pandas as pd
import time

# Geocoder
geolocator = Nominatim(user_agent="geoapi")
geocoded_landmarks = {}  # Cache for geocoded landmarks

def fetch_lat_long(address):
    """Fetch latitude and longitude for a given address."""
    if address in geocoded_landmarks:
        return geocoded_landmarks[address]
    try:
        location = geolocator.geocode(address)
        if location:
            geocoded_landmarks[address] = (location.latitude, location.longitude)
            return location.latitude, location.longitude
    except Exception as e:
        pass
    geocoded_landmarks[address] = (None, None)
    return None, None

def infer_coords_from_landmarks(missing_coords_landmarks, geocoded_df):
    """Infer latitude and longitude for area_en using nearest_landmark_en."""
    updated_geocoded_df = geocoded_df.copy()
    for index, row in missing_coords_landmarks.iterrows():
        area = row['area_en']
        for landmark in row['landmarks']:
            # Skip 'Unknown' landmarks
            if landmark == "Unknown":
                continue
            lat, lon = fetch_lat_long(landmark)
            if lat is not None and lon is not None:
                print(f"Found coordinates for {area} using landmark {landmark}: ({lat}, {lon})")
                updated_geocoded_df.loc[updated_geocoded_df['area_en'] == area, ['latitude', 'longitude']] = lat, lon
                break  # Move to the next area_en after finding coordinates
        time.sleep(1)  # Avoid overloading the API
    return updated_geocoded_df

# Step 1: Group landmarks by area_en
missing_coords_landmarks = remaining_missing_landmarks.merge(
    sales_data[['area_en', 'nearest_landmark_en']].drop_duplicates(),
    on='area_en',
)
missing_coords_landmarks = missing_coords_landmarks.groupby('area_en')['nearest_landmark_en'].apply(list).reset_index(name='landmarks')

# Step 2: Infer coordinates for areas with missing values
updated_geocoded_df_landmarks = infer_coords_from_landmarks(missing_coords_landmarks, updated_geocoded_df_landmarks)

# Step 3: Save the updated geocoded DataFrame
updated_geocoded_df_landmarks.to_csv("updated_geocoded_areas_landmarks.csv", index=False)

# Display remaining missing coordinates
remaining_missing_landmarks = updated_geocoded_df_landmarks[
    updated_geocoded_df_landmarks['latitude'].isnull() & updated_geocoded_df_landmarks['longitude'].isnull()
]
print(f"Number of area_en with missing coordinates after inferring from landmarks: {len(remaining_missing_landmarks)}")



remaining_missing_landmarks


updated_geocoded_df_landmarks.info()



